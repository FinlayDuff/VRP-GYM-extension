{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import the packages and modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gym_vrp.envs import SantaIRPEnv\n",
    "from agents.ff_sdp_agent import SDPAgentFF\n",
    "\n",
    "import torch\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Start Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "State size: torch.Size([64, 7, 6])\n",
      "1\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Expected parameter probs (Tensor of shape (64, 7)) of distribution Categorical(probs: torch.Size([64, 7])) to satisfy the constraint Simplex(), but found invalid values:\ntensor([[0.1649, 0.1540, 0.1554, 0.1642, 0.1739, 0.1877, 0.0000],\n        [0.0000, 0.1535, 0.1595, 0.1591, 0.1765, 0.1871, 0.1643],\n        [   nan,    nan,    nan,    nan,    nan,    nan,    nan],\n        [0.1741, 0.1604, 0.1620, 0.1620, 0.1751, 0.0000, 0.1665],\n        [   nan,    nan,    nan,    nan,    nan,    nan,    nan],\n        [0.1739, 0.1502, 0.0000, 0.1644, 0.1708, 0.1804, 0.1603],\n        [0.1651, 0.1554, 0.1529, 0.1703, 0.0000, 0.1906, 0.1656],\n        [0.0000, 0.1591, 0.1603, 0.1517, 0.1782, 0.1867, 0.1640],\n        [0.1690, 0.1531, 0.1541, 0.1730, 0.0000, 0.1849, 0.1660],\n        [0.1714, 0.1618, 0.1610, 0.1633, 0.1732, 0.0000, 0.1693],\n        [0.1668, 0.1512, 0.1584, 0.1633, 0.1730, 0.1873, 0.0000],\n        [0.1738, 0.1479, 0.1625, 0.0000, 0.1743, 0.1851, 0.1563],\n        [0.1682, 0.1540, 0.1567, 0.1695, 0.0000, 0.1882, 0.1634],\n        [0.1699, 0.1496, 0.0000, 0.1638, 0.1740, 0.1825, 0.1602],\n        [0.1756, 0.1621, 0.1615, 0.1589, 0.1700, 0.0000, 0.1720],\n        [0.1737, 0.1452, 0.1653, 0.0000, 0.1723, 0.1856, 0.1578],\n        [0.1731, 0.1615, 0.1594, 0.1605, 0.1736, 0.0000, 0.1718],\n        [0.1650, 0.1548, 0.1550, 0.1708, 0.0000, 0.1869, 0.1675],\n        [0.1670, 0.1553, 0.1555, 0.1616, 0.1740, 0.1867, 0.0000],\n        [0.1702, 0.1524, 0.1557, 0.1687, 0.0000, 0.1887, 0.1642],\n        [0.1716, 0.1475, 0.1627, 0.0000, 0.1735, 0.1844, 0.1603],\n        [0.1667, 0.1535, 0.1579, 0.1672, 0.0000, 0.1911, 0.1636],\n        [0.1745, 0.1467, 0.1618, 0.0000, 0.1724, 0.1885, 0.1561],\n        [0.1657, 0.1508, 0.1600, 0.1619, 0.1756, 0.1861, 0.0000],\n        [0.1702, 0.1533, 0.0000, 0.1622, 0.1692, 0.1843, 0.1607],\n        [0.1711, 0.1503, 0.0000, 0.1636, 0.1706, 0.1816, 0.1627],\n        [0.1644, 0.1522, 0.1599, 0.1642, 0.1729, 0.1864, 0.0000],\n        [0.0000, 0.1583, 0.1602, 0.1519, 0.1782, 0.1848, 0.1666],\n        [0.1654, 0.0000, 0.1588, 0.1623, 0.1671, 0.1852, 0.1613],\n        [0.1718, 0.1517, 0.1563, 0.1629, 0.0000, 0.1919, 0.1654],\n        [0.1779, 0.1588, 0.1631, 0.1608, 0.1707, 0.0000, 0.1686],\n        [0.1661, 0.1517, 0.1596, 0.1648, 0.1703, 0.1875, 0.0000],\n        [0.1721, 0.1437, 0.1654, 0.0000, 0.1740, 0.1856, 0.1592],\n        [0.1749, 0.1607, 0.1616, 0.1591, 0.1741, 0.0000, 0.1695],\n        [0.1676, 0.1519, 0.1558, 0.1655, 0.0000, 0.1945, 0.1646],\n        [0.1741, 0.1595, 0.1642, 0.1611, 0.1725, 0.0000, 0.1686],\n        [0.1697, 0.0000, 0.1618, 0.1613, 0.1642, 0.1846, 0.1583],\n        [0.1733, 0.1464, 0.1620, 0.0000, 0.1752, 0.1831, 0.1599],\n        [0.1734, 0.1434, 0.1633, 0.0000, 0.1766, 0.1850, 0.1583],\n        [0.1673, 0.0000, 0.1620, 0.1541, 0.1664, 0.1866, 0.1636],\n        [0.1660, 0.1543, 0.1595, 0.1618, 0.1731, 0.1853, 0.0000],\n        [0.0000, 0.1563, 0.1604, 0.1569, 0.1720, 0.1903, 0.1641],\n        [0.1754, 0.1605, 0.1609, 0.1579, 0.1746, 0.0000, 0.1707],\n        [0.0000, 0.1527, 0.1579, 0.1595, 0.1796, 0.1818, 0.1684],\n        [0.1670, 0.1521, 0.1528, 0.1690, 0.0000, 0.1910, 0.1679],\n        [0.0000, 0.1543, 0.1591, 0.1563, 0.1760, 0.1890, 0.1653],\n        [0.1733, 0.1611, 0.1639, 0.1627, 0.1739, 0.0000, 0.1651],\n        [0.1736, 0.1635, 0.1613, 0.1611, 0.1746, 0.0000, 0.1659],\n        [0.1653, 0.0000, 0.1599, 0.1584, 0.1665, 0.1919, 0.1581],\n        [0.1703, 0.1537, 0.0000, 0.1620, 0.1686, 0.1851, 0.1602],\n        [0.0000, 0.1589, 0.1546, 0.1560, 0.1752, 0.1862, 0.1691],\n        [0.1671, 0.1513, 0.1552, 0.1679, 0.0000, 0.1922, 0.1663],\n        [0.1670, 0.0000, 0.1592, 0.1633, 0.1641, 0.1844, 0.1621],\n        [0.1670, 0.0000, 0.1559, 0.1568, 0.1678, 0.1864, 0.1660],\n        [0.1653, 0.1564, 0.1571, 0.1609, 0.1711, 0.1892, 0.0000],\n        [0.1711, 0.1480, 0.1614, 0.0000, 0.1710, 0.1918, 0.1567],\n        [0.1666, 0.1531, 0.1554, 0.1689, 0.0000, 0.1892, 0.1668],\n        [0.1670, 0.1519, 0.0000, 0.1648, 0.1712, 0.1838, 0.1613],\n        [0.1648, 0.1544, 0.1545, 0.1667, 0.0000, 0.1901, 0.1695],\n        [0.1714, 0.1474, 0.1611, 0.0000, 0.1713, 0.1894, 0.1593],\n        [0.0000, 0.1546, 0.1560, 0.1580, 0.1758, 0.1891, 0.1665],\n        [0.0000, 0.1549, 0.1586, 0.1547, 0.1776, 0.1876, 0.1666],\n        [0.1633, 0.1546, 0.1566, 0.1653, 0.1723, 0.1879, 0.0000],\n        [0.0000, 0.1564, 0.1571, 0.1607, 0.1703, 0.1874, 0.1681]],\n       grad_fn=<DivBackward0>)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 26\u001b[0m\n\u001b[0;32m     22\u001b[0m agent_santa_ff \u001b[38;5;241m=\u001b[39m SDPAgentFF(node_dim\u001b[38;5;241m=\u001b[39mnum_nodes,hidden_dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m512\u001b[39m,\n\u001b[0;32m     23\u001b[0m     seed\u001b[38;5;241m=\u001b[39mseed, csv_path\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m./train_logs/loss_log_santa_ff_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_nodes\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mseed\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     24\u001b[0m )\n\u001b[0;32m     25\u001b[0m \u001b[38;5;66;03m# Train the agent\u001b[39;00m\n\u001b[1;32m---> 26\u001b[0m \u001b[43magent_santa_ff\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     27\u001b[0m \u001b[43m    \u001b[49m\u001b[43menv_santa_ff\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     28\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepisodes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_epochs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     29\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcheck_point_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m./check_points/santa_ff_\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mnum_nodes\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m_\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mseed\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m/\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     30\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\jfgal\\Code\\VRP-GYM-extension\\agents\\ff_sdp_agent.py:128\u001b[0m, in \u001b[0;36mSDPAgentFF.train\u001b[1;34m(self, env, episodes, check_point_dir)\u001b[0m\n\u001b[0;32m    125\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m episode \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(episodes):\n\u001b[0;32m    126\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[1;32m--> 128\u001b[0m     rewards, log_probs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43menv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    130\u001b[0m     \u001b[38;5;66;03m# Compute discounted rewards (returns)\u001b[39;00m\n\u001b[0;32m    131\u001b[0m     discounted_rewards \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdiscount_rewards(rewards)\n",
      "File \u001b[1;32mc:\\Users\\jfgal\\Code\\VRP-GYM-extension\\agents\\ff_sdp_agent.py:212\u001b[0m, in \u001b[0;36mSDPAgentFF.step\u001b[1;34m(self, env, rollouts)\u001b[0m\n\u001b[0;32m    208\u001b[0m env\u001b[38;5;241m.\u001b[39mreset()\n\u001b[0;32m    209\u001b[0m \u001b[38;5;66;03m# env_baseline = deepcopy(env)\u001b[39;00m\n\u001b[0;32m    210\u001b[0m \n\u001b[0;32m    211\u001b[0m \u001b[38;5;66;03m# Go through graph batch and get loss\u001b[39;00m\n\u001b[1;32m--> 212\u001b[0m loss, log_prob \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43menv\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    213\u001b[0m \u001b[38;5;66;03m# with torch.no_grad():\u001b[39;00m\n\u001b[0;32m    214\u001b[0m \u001b[38;5;66;03m#     loss_b, _ = self.target_model(env_baseline, rollouts[0])\u001b[39;00m\n\u001b[0;32m    216\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m loss, log_prob\n",
      "File \u001b[1;32mc:\\Users\\jfgal\\anaconda3\\envs\\gym_vrp\\lib\\site-packages\\torch\\nn\\modules\\module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\jfgal\\anaconda3\\envs\\gym_vrp\\lib\\site-packages\\torch\\nn\\modules\\module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\jfgal\\Code\\VRP-GYM-extension\\agents\\ff_sdp_agent.py:66\u001b[0m, in \u001b[0;36mFFNetwork.forward\u001b[1;34m(self, env, rollout)\u001b[0m\n\u001b[0;32m     62\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     63\u001b[0m     \u001b[38;5;66;03m# If rollout is False, sample actions stochastically\u001b[39;00m\n\u001b[0;32m     64\u001b[0m     \u001b[38;5;66;03m# Sample action from the normalized, masked probabilities for the whole batch\u001b[39;00m\n\u001b[0;32m     65\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m---> 66\u001b[0m     m \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdistributions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCategorical\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnormalized_prob\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     67\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;241m2\u001b[39m)\n\u001b[0;32m     68\u001b[0m     actions \u001b[38;5;241m=\u001b[39m m\u001b[38;5;241m.\u001b[39msample()\u001b[38;5;241m.\u001b[39munsqueeze(\n\u001b[0;32m     69\u001b[0m         \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m     70\u001b[0m     )  \u001b[38;5;66;03m# actions should have shape (batch_size, 1)\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\jfgal\\anaconda3\\envs\\gym_vrp\\lib\\site-packages\\torch\\distributions\\categorical.py:70\u001b[0m, in \u001b[0;36mCategorical.__init__\u001b[1;34m(self, probs, logits, validate_args)\u001b[0m\n\u001b[0;32m     66\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_events \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_param\u001b[38;5;241m.\u001b[39msize()[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m     67\u001b[0m batch_shape \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_param\u001b[38;5;241m.\u001b[39msize()[:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_param\u001b[38;5;241m.\u001b[39mndimension() \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mSize()\n\u001b[0;32m     69\u001b[0m )\n\u001b[1;32m---> 70\u001b[0m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mbatch_shape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidate_args\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidate_args\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\jfgal\\anaconda3\\envs\\gym_vrp\\lib\\site-packages\\torch\\distributions\\distribution.py:68\u001b[0m, in \u001b[0;36mDistribution.__init__\u001b[1;34m(self, batch_shape, event_shape, validate_args)\u001b[0m\n\u001b[0;32m     66\u001b[0m         valid \u001b[38;5;241m=\u001b[39m constraint\u001b[38;5;241m.\u001b[39mcheck(value)\n\u001b[0;32m     67\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m valid\u001b[38;5;241m.\u001b[39mall():\n\u001b[1;32m---> 68\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m     69\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpected parameter \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mparam\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     70\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m(\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(value)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m of shape \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtuple\u001b[39m(value\u001b[38;5;241m.\u001b[39mshape)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m) \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     71\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mof distribution \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mrepr\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     72\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mto satisfy the constraint \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mrepr\u001b[39m(constraint)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     73\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbut found invalid values:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mvalue\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     74\u001b[0m             )\n\u001b[0;32m     75\u001b[0m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m()\n",
      "\u001b[1;31mValueError\u001b[0m: Expected parameter probs (Tensor of shape (64, 7)) of distribution Categorical(probs: torch.Size([64, 7])) to satisfy the constraint Simplex(), but found invalid values:\ntensor([[0.1649, 0.1540, 0.1554, 0.1642, 0.1739, 0.1877, 0.0000],\n        [0.0000, 0.1535, 0.1595, 0.1591, 0.1765, 0.1871, 0.1643],\n        [   nan,    nan,    nan,    nan,    nan,    nan,    nan],\n        [0.1741, 0.1604, 0.1620, 0.1620, 0.1751, 0.0000, 0.1665],\n        [   nan,    nan,    nan,    nan,    nan,    nan,    nan],\n        [0.1739, 0.1502, 0.0000, 0.1644, 0.1708, 0.1804, 0.1603],\n        [0.1651, 0.1554, 0.1529, 0.1703, 0.0000, 0.1906, 0.1656],\n        [0.0000, 0.1591, 0.1603, 0.1517, 0.1782, 0.1867, 0.1640],\n        [0.1690, 0.1531, 0.1541, 0.1730, 0.0000, 0.1849, 0.1660],\n        [0.1714, 0.1618, 0.1610, 0.1633, 0.1732, 0.0000, 0.1693],\n        [0.1668, 0.1512, 0.1584, 0.1633, 0.1730, 0.1873, 0.0000],\n        [0.1738, 0.1479, 0.1625, 0.0000, 0.1743, 0.1851, 0.1563],\n        [0.1682, 0.1540, 0.1567, 0.1695, 0.0000, 0.1882, 0.1634],\n        [0.1699, 0.1496, 0.0000, 0.1638, 0.1740, 0.1825, 0.1602],\n        [0.1756, 0.1621, 0.1615, 0.1589, 0.1700, 0.0000, 0.1720],\n        [0.1737, 0.1452, 0.1653, 0.0000, 0.1723, 0.1856, 0.1578],\n        [0.1731, 0.1615, 0.1594, 0.1605, 0.1736, 0.0000, 0.1718],\n        [0.1650, 0.1548, 0.1550, 0.1708, 0.0000, 0.1869, 0.1675],\n        [0.1670, 0.1553, 0.1555, 0.1616, 0.1740, 0.1867, 0.0000],\n        [0.1702, 0.1524, 0.1557, 0.1687, 0.0000, 0.1887, 0.1642],\n        [0.1716, 0.1475, 0.1627, 0.0000, 0.1735, 0.1844, 0.1603],\n        [0.1667, 0.1535, 0.1579, 0.1672, 0.0000, 0.1911, 0.1636],\n        [0.1745, 0.1467, 0.1618, 0.0000, 0.1724, 0.1885, 0.1561],\n        [0.1657, 0.1508, 0.1600, 0.1619, 0.1756, 0.1861, 0.0000],\n        [0.1702, 0.1533, 0.0000, 0.1622, 0.1692, 0.1843, 0.1607],\n        [0.1711, 0.1503, 0.0000, 0.1636, 0.1706, 0.1816, 0.1627],\n        [0.1644, 0.1522, 0.1599, 0.1642, 0.1729, 0.1864, 0.0000],\n        [0.0000, 0.1583, 0.1602, 0.1519, 0.1782, 0.1848, 0.1666],\n        [0.1654, 0.0000, 0.1588, 0.1623, 0.1671, 0.1852, 0.1613],\n        [0.1718, 0.1517, 0.1563, 0.1629, 0.0000, 0.1919, 0.1654],\n        [0.1779, 0.1588, 0.1631, 0.1608, 0.1707, 0.0000, 0.1686],\n        [0.1661, 0.1517, 0.1596, 0.1648, 0.1703, 0.1875, 0.0000],\n        [0.1721, 0.1437, 0.1654, 0.0000, 0.1740, 0.1856, 0.1592],\n        [0.1749, 0.1607, 0.1616, 0.1591, 0.1741, 0.0000, 0.1695],\n        [0.1676, 0.1519, 0.1558, 0.1655, 0.0000, 0.1945, 0.1646],\n        [0.1741, 0.1595, 0.1642, 0.1611, 0.1725, 0.0000, 0.1686],\n        [0.1697, 0.0000, 0.1618, 0.1613, 0.1642, 0.1846, 0.1583],\n        [0.1733, 0.1464, 0.1620, 0.0000, 0.1752, 0.1831, 0.1599],\n        [0.1734, 0.1434, 0.1633, 0.0000, 0.1766, 0.1850, 0.1583],\n        [0.1673, 0.0000, 0.1620, 0.1541, 0.1664, 0.1866, 0.1636],\n        [0.1660, 0.1543, 0.1595, 0.1618, 0.1731, 0.1853, 0.0000],\n        [0.0000, 0.1563, 0.1604, 0.1569, 0.1720, 0.1903, 0.1641],\n        [0.1754, 0.1605, 0.1609, 0.1579, 0.1746, 0.0000, 0.1707],\n        [0.0000, 0.1527, 0.1579, 0.1595, 0.1796, 0.1818, 0.1684],\n        [0.1670, 0.1521, 0.1528, 0.1690, 0.0000, 0.1910, 0.1679],\n        [0.0000, 0.1543, 0.1591, 0.1563, 0.1760, 0.1890, 0.1653],\n        [0.1733, 0.1611, 0.1639, 0.1627, 0.1739, 0.0000, 0.1651],\n        [0.1736, 0.1635, 0.1613, 0.1611, 0.1746, 0.0000, 0.1659],\n        [0.1653, 0.0000, 0.1599, 0.1584, 0.1665, 0.1919, 0.1581],\n        [0.1703, 0.1537, 0.0000, 0.1620, 0.1686, 0.1851, 0.1602],\n        [0.0000, 0.1589, 0.1546, 0.1560, 0.1752, 0.1862, 0.1691],\n        [0.1671, 0.1513, 0.1552, 0.1679, 0.0000, 0.1922, 0.1663],\n        [0.1670, 0.0000, 0.1592, 0.1633, 0.1641, 0.1844, 0.1621],\n        [0.1670, 0.0000, 0.1559, 0.1568, 0.1678, 0.1864, 0.1660],\n        [0.1653, 0.1564, 0.1571, 0.1609, 0.1711, 0.1892, 0.0000],\n        [0.1711, 0.1480, 0.1614, 0.0000, 0.1710, 0.1918, 0.1567],\n        [0.1666, 0.1531, 0.1554, 0.1689, 0.0000, 0.1892, 0.1668],\n        [0.1670, 0.1519, 0.0000, 0.1648, 0.1712, 0.1838, 0.1613],\n        [0.1648, 0.1544, 0.1545, 0.1667, 0.0000, 0.1901, 0.1695],\n        [0.1714, 0.1474, 0.1611, 0.0000, 0.1713, 0.1894, 0.1593],\n        [0.0000, 0.1546, 0.1560, 0.1580, 0.1758, 0.1891, 0.1665],\n        [0.0000, 0.1549, 0.1586, 0.1547, 0.1776, 0.1876, 0.1666],\n        [0.1633, 0.1546, 0.1566, 0.1653, 0.1723, 0.1879, 0.0000],\n        [0.0000, 0.1564, 0.1571, 0.1607, 0.1703, 0.1874, 0.1681]],\n       grad_fn=<DivBackward0>)"
     ]
    }
   ],
   "source": [
    "# Original\n",
    "# batch_size = 256\n",
    "# seed = 69\n",
    "# num_nodes = 20\n",
    "\n",
    "# Quick Test\n",
    "# batch_size = 10\n",
    "# seed = 23\n",
    "# num_nodes = 5\n",
    "\n",
    "batch_size = 64\n",
    "seed = 23\n",
    "num_nodes = 7\n",
    "\n",
    "num_epochs = 251\n",
    "# num_epochs = 251\n",
    "\n",
    "# Instantiate the SantaIRPEnv environment\n",
    "env_santa_ff = SantaIRPEnv(num_nodes=num_nodes, batch_size=batch_size, seed=seed)\n",
    "\n",
    "# Instantiate the SDPAgentFF\n",
    "agent_santa_ff = SDPAgentFF(node_dim=num_nodes,hidden_dim=512,\n",
    "    seed=seed, csv_path=f\"./train_logs/loss_log_santa_ff_{num_nodes}_{seed}.csv\",\n",
    ")\n",
    "# Train the agent\n",
    "agent_santa_ff.train(\n",
    "    env_santa_ff,\n",
    "    episodes=num_epochs,\n",
    "    check_point_dir=f\"./check_points/santa_ff_{num_nodes}_{seed}/\",\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualise the actions of the agent in the environments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#env = SantaIRPEnv(num_nodes=num_nodes, batch_size=batch_size, seed=seed, num_draw=3)\n",
    "env = env_santa_ff\n",
    "TSPModel=f'./check_points/tsp_{num_nodes}_{seed}/model_epoch_{num_epochs-1}.pt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup for evaluation\n",
    "env.enable_video_capturing(\n",
    "    video_save_path=f\"./videos/video_test_santa_ff_{num_nodes}_{seed}.mp4\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# agent = SDPAgentFF(seed=seed)\n",
    "agent_santa_ff.model.load_state_dict(torch.load(f\"./check_points/santa_ff_{num_nodes}_{seed}/model_epoch_{num_epochs-1}.pt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the agent\n",
    "loss_a = agent_santa_ff.evaluate(env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Close the video recorder\n",
    "env.vid.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load the CSV file\n",
    "csv_path = f\"./train_logs/loss_log_santa_ff_{num_nodes}_{seed}.csv\"\n",
    "data = pd.read_csv(csv_path)\n",
    "\n",
    "# Extract the 'Epoch' and 'Loss' columns\n",
    "epochs = data['Epoch']\n",
    "loss = data['Loss']\n",
    "\n",
    "# Create the plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(epochs, loss, label='Training Loss', color='blue')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training Loss over Epochs')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rl_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
